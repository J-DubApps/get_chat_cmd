#!/bin/bash
#
# Example configuration file for ai_bash_commands.sh
#
# Copy this file to ~/.config/ai_bash_config.sh and fill in your API keys.
# Make sure the file is not world-readable (chmod 600 ~/.config/ai_bash_config.sh)
#

# --- API Keys ---

# OpenRouter API Key (Required for get_chat_cmd1)
# Get yours from https://openrouter.ai/keys
export OPENROUTER_API_KEY="YOUR_OPENROUTER_API_KEY"

# OpenAI API Key (Required for get_chat_cmd2)
# Get yours from https://platform.openai.com/api-keys
export OPENAI_API_KEY="YOUR_OPENAI_API_KEY"

# Anthropic API Key (Required for get_chat_cmd3)
# Get yours from https://console.anthropic.com/settings/keys
export ANTHROPIC_API_KEY="YOUR_ANTHROPIC_API_KEY"

# --- Local Model Configuration ---

# Base URL for your locally hosted model API (e.g., LM Studio, Ollama)
# Required for get_chat_local
export LOCAL_MODEL_API_BASE="http://localhost:1234/v1" # Example for LM Studio

# Optional: API Key for your local model if required
# export LOCAL_MODEL_API_KEY="YOUR_LOCAL_MODEL_API_KEY"

# --- Model Selection (Optional - Defaults can be set in the main script) ---

# Default models to use for each provider
# export OPENROUTER_MODEL="openrouter/auto" # Or specify a model like "anthropic/claude-3-haiku"
# export OPENAI_MODEL="gpt-4o-mini"
# export ANTHROPIC_MODEL="claude-3-haiku-20240307"
# export LOCAL_MODEL_NAME="local-model" # Model name expected by your local API

# --- Other Settings ---

# Preferred HTTP client ('curl' or 'wget') - script will auto-detect if not set
# export PREFERRED_HTTP_CLIENT="curl"

# Preferred JSON parser ('jq' or 'python') - script will auto-detect if not set
# export PREFERRED_JSON_PARSER="jq"

# Enable/disable clipboard functionality ('true' or 'false') - defaults to true if tools exist
# export ENABLE_CLIPBOARD="true"
